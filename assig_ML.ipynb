{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nadia147/ML_boundary/blob/main/assig_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "VC6qE8D4MCVl",
        "outputId": "bbd85e13-979b-400c-cff6-3137c93443e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: earthpy in /usr/local/lib/python3.10/dist-packages (0.9.4)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.10/dist-packages (from earthpy) (0.13.2)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from earthpy) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from earthpy) (1.23.5)\n",
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.10/dist-packages (from earthpy) (1.3.8)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from earthpy) (0.19.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from earthpy) (2.31.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->earthpy) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->earthpy) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->earthpy) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->earthpy) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->earthpy) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->earthpy) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->earthpy) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->earthpy) (2.8.2)\n",
            "Requirement already satisfied: fiona>=1.8.19 in /usr/local/lib/python3.10/dist-packages (from geopandas->earthpy) (1.9.4.post1)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from geopandas->earthpy) (1.5.3)\n",
            "Requirement already satisfied: pyproj>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from geopandas->earthpy) (3.6.0)\n",
            "Requirement already satisfied: shapely>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from geopandas->earthpy) (2.0.1)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.10/dist-packages (from rasterio->earthpy) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio->earthpy) (23.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio->earthpy) (2023.7.22)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio->earthpy) (8.1.7)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio->earthpy) (0.7.2)\n",
            "Requirement already satisfied: snuggs>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from rasterio->earthpy) (1.4.7)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio->earthpy) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio->earthpy) (67.7.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->earthpy) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->earthpy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->earthpy) (2.0.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->earthpy) (1.11.2)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->earthpy) (3.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->earthpy) (2.31.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->earthpy) (2023.8.30)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->earthpy) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas->earthpy) (1.16.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->geopandas->earthpy) (2023.3.post1)\n",
            "Requirement already satisfied: spectral in /usr/local/lib/python3.10/dist-packages (0.23.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from spectral) (1.23.5)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.24.1.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "! pip install earthpy\n",
        "# Colab Requirements\n",
        "!pip install spectral\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "## Basics\n",
        "import gc\n",
        "gc.collect()\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import time\n",
        "import numpy\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from operator import truediv\n",
        "import scipy.io as sio\n",
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import spectral\n",
        "## Ploting\n",
        "from plotly.offline import init_notebook_mode\n",
        "import plotly.graph_objs as go\n",
        "from matplotlib.pyplot import cm\n",
        "import matplotlib.pyplot as plt\n",
        "init_notebook_mode(connected=True)\n",
        "%matplotlib inline\n",
        "## Sklearn\n",
        "import sklearn as sk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
        "from sklearn.decomposition import IncrementalPCA\n",
        "## Deep Model\n",
        "import keras\n",
        "import h5py\n",
        "from keras.layers import Dropout, Input, Conv2D, Conv3D, MaxPool3D, Flatten, Dense, Reshape, BatchNormalization\n",
        "from plotly.offline import iplot, init_notebook_mode\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adadelta\n",
        "from keras.models import Sequential, Model\n",
        "#from keras.utils import np_utils\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "## Mounting Colab\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "drive.mount('/content/drive')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import earthpy.plot as ep\n",
        "import seaborn as sns\n",
        "import earthpy.spatial as es\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "from scipy.io import loadmat\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (accuracy_score,\n",
        "                             confusion_matrix, classification_report)\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "from tqdm import tqdm\n",
        "import scipy.io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LNCms1blCw7-"
      },
      "outputs": [],
      "source": [
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "\n",
        "config = ConfigProto()\n",
        "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aa3YPga7Cz59"
      },
      "outputs": [],
      "source": [
        "# import the libraries as shown below\n",
        "\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "#from keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "#import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tW9CxybFC7ae",
        "outputId": "7abbad5b-4219-497d-d3b6-64cfc4a809f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# re-size all the images to this\n",
        "IMAGE_SIZE = [224, 224]\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define file paths for your data directories\n",
        "train_dir = '/content/drive/MyDrive/Colab Notebooks/train'\n",
        "label_dir = '/content/drive/MyDrive/Colab Notebooks/labels'\n",
        "test_dir = '/content/drive/MyDrive/Colab Notebooks/private'\n",
        "\n",
        "train_path = '/content/drive/MyDrive/Colab Notebooks/train'\n",
        "valid_path = '/content/drive/MyDrive/Colab Notebooks/private'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlAzqvKfC_PS",
        "outputId": "9705f1f3-1855-4209-f278-db7a36451852"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/normalization/batch_normalization.py:883: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 4s 0us/step\n"
          ]
        }
      ],
      "source": [
        "resnet = ResNet50(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jcogRSBfC__s"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# don't train existing weights\n",
        "for layer in resnet.layers:\n",
        "    layer.trainable = False\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iHvZVqzqDDDA"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "  # useful for getting number of output classes\n",
        "folders = glob('/content/drive/MyDrive/Colab Notebooks/train/*')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VmBnv3MoDGbf"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# our layers - you can add more if you want\n",
        "x = Flatten()(resnet.output)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kKvWO2_tDJEf"
      },
      "outputs": [],
      "source": [
        "prediction = Dense(len(folders), activation='softmax')(x)\n",
        "\n",
        "# create a model object\n",
        "#model = Model(inputs=resnet.input, outputs=prediction)\n",
        "\n",
        "\n",
        "# view the structure of the model\n",
        "#model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3rKE8TAJVXwu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaezLeoBMtbQ",
        "outputId": "74e9c26f-6a45-4f74-e67a-6a67160c5505"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 222, 222, 8)       224       \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 394272)            0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6)                 2365638   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 6)                 0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 42        \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 6)                 0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 6)                 42        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2365946 (9.03 MB)\n",
            "Trainable params: 2365946 (9.03 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import scipy.io\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from keras.utils import np_utils\n",
        "from keras.layers import Input, Conv3D,Conv2D, Flatten, Dense, Dropout\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "#import time\n",
        "# Model Structure\n",
        "input_layer = resnet.input\n",
        "conv_layer1 = Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(input_layer)\n",
        "\n",
        "\n",
        "flatten_layer = Flatten()(conv_layer1)\n",
        "dense_layer1 = Dense(units=6, activation='relu')(flatten_layer)\n",
        "dense_layer1 = Dropout(0.4)(dense_layer1)\n",
        "dense_layer2 = Dense(units=6, activation='relu')(dense_layer1)\n",
        "dense_layer2 = Dropout(0.4)(dense_layer2)\n",
        "output_layer = Dense(units=6, activation='softmax')(dense_layer2)\n",
        "\n",
        "# Define the model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "4GjYz9UGDY5A"
      },
      "outputs": [],
      "source": [
        "\n",
        "# tell the model what cost and optimization method to use\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "X7x-maKBDZ2H"
      },
      "outputs": [],
      "source": [
        "# Use the Image Data Generator to import the images from the dataset\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtiWMyemDdhk",
        "outputId": "19cde0ff-e2b3-469f-9983-be5c9a03481b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 760 images belonging to 6 classes.\n"
          ]
        }
      ],
      "source": [
        "# Make sure you provide the same target size as initialied for the image size\n",
        "training_set = train_datagen.flow_from_directory(train_path,\n",
        "                                                 target_size = (256, 256),\n",
        "                                                 batch_size = 16,\n",
        "                                                 class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBAKR6dhFkTV",
        "outputId": "4395a3a8-4c42-41af-ec65-adc3c57c4a53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 760 images belonging to 6 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the data augmentation parameters\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,     # Normalize pixel values to [0, 1]\n",
        "    shear_range=0.2,    # Shear transformations\n",
        "    zoom_range=0.2,     # Zoom transformations\n",
        "    horizontal_flip=True)  # Horizontal flips\n",
        "\n",
        "# Provide the path to your dataset directory in Colab\n",
        "dataset_path = '/content/drive/MyDrive/Colab Notebooks/train'  # Change this to your actual dataset path\n",
        "\n",
        "# Create a generator for the training set\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=(224, 224),  # Set your desired target size\n",
        "    batch_size=16,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXpYI4PADjDM",
        "outputId": "36b26c0f-86f0-4fa7-c1bf-c50f93949a00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 760 images belonging to 6 classes.\n"
          ]
        }
      ],
      "source": [
        "test_set = test_datagen.flow_from_directory(dataset_path,\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 16,\n",
        "                                            class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDt3yPbuDkEj",
        "outputId": "512414ed-8f27-43dc-9e8f-430f07b8aaad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "48/48 [==============================] - 344s 7s/step - batch: 23.5000 - size: 15.8333 - loss: 5.3926 - acc: 0.2658 - val_loss: 1.7660 - val_acc: 0.2684\n",
            "Epoch 2/30\n",
            "48/48 [==============================] - 13s 273ms/step - batch: 23.5000 - size: 15.8333 - loss: 1.7540 - acc: 0.2618 - val_loss: 1.7411 - val_acc: 0.2684\n",
            "Epoch 3/30\n",
            "48/48 [==============================] - 13s 266ms/step - batch: 23.5000 - size: 15.8333 - loss: 1.7299 - acc: 0.2684 - val_loss: 1.7175 - val_acc: 0.2684\n",
            "Epoch 4/30\n",
            "48/48 [==============================] - 13s 266ms/step - batch: 23.5000 - size: 15.8333 - loss: 1.7070 - acc: 0.2605 - val_loss: 1.6954 - val_acc: 0.2684\n",
            "Epoch 5/30\n",
            "48/48 [==============================] - 13s 272ms/step - batch: 23.5000 - size: 15.8333 - loss: 1.6865 - acc: 0.2645 - val_loss: 1.6749 - val_acc: 0.2684\n",
            "Epoch 6/30\n",
            "48/48 [==============================] - 13s 273ms/step - batch: 23.5000 - size: 15.8333 - loss: 1.6664 - acc: 0.2697 - val_loss: 1.6558 - val_acc: 0.2684\n",
            "Epoch 7/30\n",
            "48/48 [==============================] - 13s 272ms/step - batch: 23.5000 - size: 15.8333 - loss: 1.6463 - acc: 0.2697 - val_loss: 1.6375 - val_acc: 0.2684\n",
            "Epoch 8/30\n",
            "48/48 [==============================] - 13s 273ms/step - batch: 23.5000 - size: 15.8333 - loss: 1.6333 - acc: 0.2526 - val_loss: 1.6212 - val_acc: 0.2684\n",
            "Epoch 9/30\n",
            "48/48 [==============================] - ETA: 0s - batch: 23.5000 - size: 15.8333 - loss: 1.6160 - acc: 0.2776"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# fit the model\n",
        "# Run the cell. It will take some time to execute\n",
        "r = model.fit_generator(\n",
        "  training_set,\n",
        "  validation_data=test_set,\n",
        "  epochs=30,\n",
        "  steps_per_epoch=len(training_set),\n",
        "  validation_steps=len(test_set)\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L82W8sAXZd3E"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPz4xY8G2ndScTTEhrzHR9z",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}